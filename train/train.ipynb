{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset import  CustomDataset\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import threading\n",
    "import random\n",
    "# import rasterio\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "from sklearn.utils import shuffle as shuffle_lists\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "\n",
    "import torch\n",
    "\n",
    "#default\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#trasnform\n",
    "from torchvision import transforms\n",
    "\n",
    "#dataset\n",
    "from utils.dataset import CustomDataset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "\n",
    "from utils import models \n",
    "#metric\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_curve, auc\n",
    "import torchmetrics.functional as tf\n",
    "\n",
    "#numeric\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "#visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#system \n",
    "from tqdm import tqdm\n",
    "import os \n",
    "import wandb\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "############################## SAVE TIME ##############################\n",
      "############################## 202403141808 ##############################\n"
     ]
    }
   ],
   "source": [
    "now = datetime.datetime.now()\n",
    "weekday = now.strftime(\"%A\")  # %A는 현재 요일을 나타내는 포맷 지정자입니다.\n",
    "formatted_now = now.strftime(\"%Y%m%d%H%M\")\n",
    "checkpoint_datetime = formatted_now\n",
    "print(f\"#\"*30, \"SAVE TIME\", \"#\"*30)\n",
    "print(f\"#\"*30, checkpoint_datetime, \"#\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = '../../dataset/train_meta.csv'\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # transforms.Resize((512,512), antialias= True),\n",
    "    # transforms.RandomApply([\n",
    "    #     transforms.RandomRotation(degrees = 30),\n",
    "    #     transforms.RandomVerticalFlip(p= 0.5),\n",
    "    #     transforms.RandomVerticalFlip(p=0.5),\n",
    "    #     transforms.RandomCrop(size =224, scale= (0.8, 1.2), ratio = (0.75, 1.2), antialias = True),\n",
    "    #     transforms.ColorJitter(brightness= 0.2, contrast = 0.2)\n",
    "    # ]),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "tr_batch = 2\n",
    "vl_batch = 2\n",
    "\n",
    "dataset = CustomDataset(\n",
    "    csv_path= train_csv,\n",
    "    transform= None, #None으로 세팅\n",
    "    MAX_PIXEL_VALUE= 65535,\n",
    "    band = (7,6,2) #기존 세팅 \n",
    ")\n",
    "\n",
    "# 훈련 및 검증 세트 분할\n",
    "train_size = int(0.8 * len(dataset))\n",
    "valid_size = len(dataset) - train_size \n",
    "train_dataset, valid_dataset = random_split(dataset, [train_size, valid_size])\n",
    "train_loader = DataLoader(dataset = train_dataset, batch_size = tr_batch, shuffle= True)\n",
    "valid_loader = DataLoader(dataset = valid_dataset, batch_size = vl_batch, shuffle= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n",
      "(256, 256, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Invalid shape (3, 256, 256) for image data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m6\u001b[39m,\u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m121\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m122\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/matplotlib/pyplot.py:2695\u001b[0m, in \u001b[0;36mimshow\u001b[0;34m(X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, data, **kwargs)\u001b[0m\n\u001b[1;32m   2689\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Axes\u001b[38;5;241m.\u001b[39mimshow)\n\u001b[1;32m   2690\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mimshow\u001b[39m(\n\u001b[1;32m   2691\u001b[0m         X, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, aspect\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, interpolation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2692\u001b[0m         alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, vmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, extent\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2693\u001b[0m         interpolation_stage\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, filternorm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filterrad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4.0\u001b[39m,\n\u001b[1;32m   2694\u001b[0m         resample\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, url\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m-> 2695\u001b[0m     __ret \u001b[38;5;241m=\u001b[39m \u001b[43mgca\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimshow\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcmap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcmap\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maspect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maspect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2697\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvmin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvmax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvmax\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2699\u001b[0m \u001b[43m        \u001b[49m\u001b[43minterpolation_stage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation_stage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilternorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilternorm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilterrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilterrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2701\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2702\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2703\u001b[0m     sci(__ret)\n\u001b[1;32m   2704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m __ret\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/matplotlib/__init__.py:1446\u001b[0m, in \u001b[0;36m_preprocess_data.<locals>.inner\u001b[0;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1443\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m   1444\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(ax, \u001b[38;5;241m*\u001b[39margs, data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1445\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1446\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msanitize_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1448\u001b[0m     bound \u001b[38;5;241m=\u001b[39m new_sig\u001b[38;5;241m.\u001b[39mbind(ax, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1449\u001b[0m     auto_label \u001b[38;5;241m=\u001b[39m (bound\u001b[38;5;241m.\u001b[39marguments\u001b[38;5;241m.\u001b[39mget(label_namer)\n\u001b[1;32m   1450\u001b[0m                   \u001b[38;5;129;01mor\u001b[39;00m bound\u001b[38;5;241m.\u001b[39mkwargs\u001b[38;5;241m.\u001b[39mget(label_namer))\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/matplotlib/axes/_axes.py:5663\u001b[0m, in \u001b[0;36mAxes.imshow\u001b[0;34m(self, X, cmap, norm, aspect, interpolation, alpha, vmin, vmax, origin, extent, interpolation_stage, filternorm, filterrad, resample, url, **kwargs)\u001b[0m\n\u001b[1;32m   5655\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_aspect(aspect)\n\u001b[1;32m   5656\u001b[0m im \u001b[38;5;241m=\u001b[39m mimage\u001b[38;5;241m.\u001b[39mAxesImage(\u001b[38;5;28mself\u001b[39m, cmap\u001b[38;5;241m=\u001b[39mcmap, norm\u001b[38;5;241m=\u001b[39mnorm,\n\u001b[1;32m   5657\u001b[0m                       interpolation\u001b[38;5;241m=\u001b[39minterpolation, origin\u001b[38;5;241m=\u001b[39morigin,\n\u001b[1;32m   5658\u001b[0m                       extent\u001b[38;5;241m=\u001b[39mextent, filternorm\u001b[38;5;241m=\u001b[39mfilternorm,\n\u001b[1;32m   5659\u001b[0m                       filterrad\u001b[38;5;241m=\u001b[39mfilterrad, resample\u001b[38;5;241m=\u001b[39mresample,\n\u001b[1;32m   5660\u001b[0m                       interpolation_stage\u001b[38;5;241m=\u001b[39minterpolation_stage,\n\u001b[1;32m   5661\u001b[0m                       \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 5663\u001b[0m \u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5664\u001b[0m im\u001b[38;5;241m.\u001b[39mset_alpha(alpha)\n\u001b[1;32m   5665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m im\u001b[38;5;241m.\u001b[39mget_clip_path() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5666\u001b[0m     \u001b[38;5;66;03m# image does not already have clipping set, clip to axes patch\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/matplotlib/image.py:710\u001b[0m, in \u001b[0;36m_ImageBase.set_data\u001b[0;34m(self, A)\u001b[0m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A[:, :, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    708\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    709\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m]):\n\u001b[0;32m--> 710\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid shape \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m for image data\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    711\u001b[0m                     \u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mshape))\n\u001b[1;32m    713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[1;32m    714\u001b[0m     \u001b[38;5;66;03m# If the input data has values outside the valid range (after\u001b[39;00m\n\u001b[1;32m    715\u001b[0m     \u001b[38;5;66;03m# normalisation), we issue a warning and then clip X to the bounds\u001b[39;00m\n\u001b[1;32m    716\u001b[0m     \u001b[38;5;66;03m# - otherwise casting wraps extreme values, hiding outliers and\u001b[39;00m\n\u001b[1;32m    717\u001b[0m     \u001b[38;5;66;03m# making reliable interpretation impossible.\u001b[39;00m\n\u001b[1;32m    718\u001b[0m     high \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m255\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_A\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39minteger) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[0;31mTypeError\u001b[0m: Invalid shape (3, 256, 256) for image data"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for images, masks in train_loader:\n",
    "    # print(images.shape)\n",
    "    idx = 0\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(images[idx])\n",
    "    plt.title('image')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(masks[idx], cmap= 'gray')\n",
    "    plt.title('mask')\n",
    "    plt.show()\n",
    "    break\n",
    "\n",
    "for images, masks in valid_loader:\n",
    "    print(images.shape)\n",
    "    idx = 0\n",
    "    plt.figure(figsize=(6,4))\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(images[idx])\n",
    "    plt.title('image')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(masks[idx], cmap= 'gray')\n",
    "    plt.title('mask')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device : cuda\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 32, 224, 224]             864\n",
      "       BatchNorm2d-2         [-1, 32, 224, 224]              64\n",
      "              ReLU-3         [-1, 32, 224, 224]               0\n",
      "            Conv2d-4         [-1, 32, 224, 224]           9,216\n",
      "       BatchNorm2d-5         [-1, 32, 224, 224]              64\n",
      "              ReLU-6         [-1, 32, 224, 224]               0\n",
      "         MaxPool2d-7         [-1, 32, 112, 112]               0\n",
      "            Conv2d-8         [-1, 64, 112, 112]          18,432\n",
      "       BatchNorm2d-9         [-1, 64, 112, 112]             128\n",
      "             ReLU-10         [-1, 64, 112, 112]               0\n",
      "           Conv2d-11         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-12         [-1, 64, 112, 112]             128\n",
      "             ReLU-13         [-1, 64, 112, 112]               0\n",
      "        MaxPool2d-14           [-1, 64, 56, 56]               0\n",
      "           Conv2d-15          [-1, 128, 56, 56]          73,728\n",
      "      BatchNorm2d-16          [-1, 128, 56, 56]             256\n",
      "             ReLU-17          [-1, 128, 56, 56]               0\n",
      "           Conv2d-18          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-19          [-1, 128, 56, 56]             256\n",
      "             ReLU-20          [-1, 128, 56, 56]               0\n",
      "        MaxPool2d-21          [-1, 128, 28, 28]               0\n",
      "           Conv2d-22          [-1, 256, 28, 28]         294,912\n",
      "      BatchNorm2d-23          [-1, 256, 28, 28]             512\n",
      "             ReLU-24          [-1, 256, 28, 28]               0\n",
      "           Conv2d-25          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-26          [-1, 256, 28, 28]             512\n",
      "             ReLU-27          [-1, 256, 28, 28]               0\n",
      "        MaxPool2d-28          [-1, 256, 14, 14]               0\n",
      "           Conv2d-29          [-1, 512, 14, 14]       1,179,648\n",
      "      BatchNorm2d-30          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-31          [-1, 512, 14, 14]               0\n",
      "           Conv2d-32          [-1, 512, 14, 14]       2,359,296\n",
      "      BatchNorm2d-33          [-1, 512, 14, 14]           1,024\n",
      "             ReLU-34          [-1, 512, 14, 14]               0\n",
      "  ConvTranspose2d-35          [-1, 256, 28, 28]         524,544\n",
      "           Conv2d-36          [-1, 256, 28, 28]       1,179,648\n",
      "      BatchNorm2d-37          [-1, 256, 28, 28]             512\n",
      "             ReLU-38          [-1, 256, 28, 28]               0\n",
      "           Conv2d-39          [-1, 256, 28, 28]         589,824\n",
      "      BatchNorm2d-40          [-1, 256, 28, 28]             512\n",
      "             ReLU-41          [-1, 256, 28, 28]               0\n",
      "  ConvTranspose2d-42          [-1, 128, 56, 56]         131,200\n",
      "           Conv2d-43          [-1, 128, 56, 56]         294,912\n",
      "      BatchNorm2d-44          [-1, 128, 56, 56]             256\n",
      "             ReLU-45          [-1, 128, 56, 56]               0\n",
      "           Conv2d-46          [-1, 128, 56, 56]         147,456\n",
      "      BatchNorm2d-47          [-1, 128, 56, 56]             256\n",
      "             ReLU-48          [-1, 128, 56, 56]               0\n",
      "  ConvTranspose2d-49         [-1, 64, 112, 112]          32,832\n",
      "           Conv2d-50         [-1, 64, 112, 112]          73,728\n",
      "      BatchNorm2d-51         [-1, 64, 112, 112]             128\n",
      "             ReLU-52         [-1, 64, 112, 112]               0\n",
      "           Conv2d-53         [-1, 64, 112, 112]          36,864\n",
      "      BatchNorm2d-54         [-1, 64, 112, 112]             128\n",
      "             ReLU-55         [-1, 64, 112, 112]               0\n",
      "  ConvTranspose2d-56         [-1, 32, 224, 224]           8,224\n",
      "           Conv2d-57         [-1, 32, 224, 224]          18,432\n",
      "      BatchNorm2d-58         [-1, 32, 224, 224]              64\n",
      "             ReLU-59         [-1, 32, 224, 224]               0\n",
      "           Conv2d-60         [-1, 32, 224, 224]           9,216\n",
      "      BatchNorm2d-61         [-1, 32, 224, 224]              64\n",
      "             ReLU-62         [-1, 32, 224, 224]               0\n",
      "           Conv2d-63          [-1, 1, 224, 224]              33\n",
      "================================================================\n",
      "Total params: 7,763,041\n",
      "Trainable params: 7,763,041\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 309.31\n",
      "Params size (MB): 29.61\n",
      "Estimated Total Size (MB): 339.50\n",
      "----------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/eiden/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "# cost func & optimizer 정의\n",
    "\n",
    "# random seed 고정\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "else:\n",
    "    device = torch.device('cuda')\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
    "\n",
    "model.to(device)\n",
    "lr = 0.0001\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr = lr)\n",
    "\n",
    "loss = nn.BCELoss()\n",
    "\n",
    "print(f'device : {device}')\n",
    "summary(model, input_size=(3, 224, 224))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {\n",
    "    'tr_bce' : [],\n",
    "    'vl_bce' : []\n",
    "}\n",
    "epoch, epochs = 0, 200\n",
    "early_stopping_epochs, early_stopping_cnt= 10, 0\n",
    "best_loss = float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/200 [00:00<?, ?it/s]\n",
      "  0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 256, 3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [32, 3, 3, 3], expected input[2, 256, 256, 3] to have 3 channels, but got 256 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m images, masks \u001b[38;5;241m=\u001b[39m images\u001b[38;5;241m.\u001b[39mto(device), masks\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(images\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m----> 8\u001b[0m preds \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m loss(preds, masks)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     12\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/torch/hub/mateuszbuda_brain-segmentation-pytorch_master/unet.py:46\u001b[0m, in \u001b[0;36mUNet.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 46\u001b[0m     enc1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m     enc2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool1(enc1))\n\u001b[1;32m     48\u001b[0m     enc3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder3(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpool2(enc2))\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/torch/nn/modules/conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/fire/lib/python3.8/site-packages/torch/nn/modules/conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [32, 3, 3, 3], expected input[2, 256, 256, 3] to have 3 channels, but got 256 channels instead"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(epoch, epochs)):\n",
    "    train_losses, valid_losses = 0., 0.\n",
    "    \n",
    "    model.train()\n",
    "    for _, (images, masks) in tqdm(enumerate(train_loader)):\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "        print(images.shape)\n",
    "        preds = model(images)\n",
    "        \n",
    "        train_loss = loss(preds, masks).to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        train_losses += train_loss.item()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for _, (images, masks) in tqdm(enumerate(train_loader)):\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            preds = model(images)\n",
    "            \n",
    "            valid_loss = loss(preds, masks).to(device)\n",
    "            valid_losses += valid_loss.item()\n",
    "            \n",
    "    metrics['tr_bce'].append(train_losses / len(train_loader))\n",
    "    metrics['vl_bce'].append(valid_losses / len(valid_loader))\n",
    "    \n",
    "    # Early Stopping\n",
    "    if valid_losses < best_loss:\n",
    "        best_loss = valid_losses\n",
    "        early_stopping_cnt = 0\n",
    "    else:\n",
    "        early_stopping_cnt += 1\n",
    "        if early_stopping_cnt >= early_stopping_epochs:\n",
    "            print(f\"Early Stops!!! : {epoch}/{epochs}\")\n",
    "    \n",
    "    # Validation 성능이 이전보다 우수한 경우 모델 저장\n",
    "    if valid_losses > np.array(metrics['vl_bce'])[:-1].max():\n",
    "        SAVE_DIR = '../result'\n",
    "        torch.save({\n",
    "            \"model\" : f\"{epoch}\",\n",
    "            \"epoch\" : epoch,\n",
    "            \"epochs\" : epochs,\n",
    "            \"model_state_dict\" : model.state_dict(),\n",
    "            \"optimizer_state_dict\" : optimizer.state_dict(),\n",
    "            \"learning_rate\" : lr,\n",
    "            \"loss\" : loss,\n",
    "            \"metric\" : metrics,\n",
    "            \"description\" : f\"segmentation model training status : {epoch}/{epochs}\"\n",
    "        },\n",
    "        f'../model/{checkpoint_datetime}.pt')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "            \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eiden",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
